{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mirei\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\mirei\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "C:\\Users\\mirei\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n",
      "C:\\Users\\mirei\\Anaconda3\\lib\\site-packages\\pandas\\compat\\_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mirei\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py:3417: DtypeWarning: Columns (5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# huntington's\n",
    "nodes_hd = pd.read_csv('final data-kg/graph_nodes_v2024-05-27.csv') #04-02\n",
    "edges_hd = pd.read_csv(\"final data-kg/graph_edges_v2024-05-27.csv\") #04-02\n",
    "pred_pairs = pd.read_csv(\"final data-kg/pairs_pred_iron_reduced.csv\")\n",
    "# pred_pairs_drugs = pd.read_csv(\"final data-kg/pairs_pred_drugs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alzheimer's\n",
    "nodes_ad = pd.read_csv('final data-kg/alz_graph_nodes_v2024-05-25.csv')#\"ALZHEIMER/monarch_nodes_v2024-05-25.csv\")\n",
    "edges_ad = pd.read_csv('final data-kg/alz_graph_edges_v2024-05-25.csv')#\"ALZHEIMER/monarch_edges_v2024-05-25.csv\")\n",
    "# ad_dist_edges = pd.read_csv('final data-kg/ad_dist_edges.csv')\n",
    "# nodes_ad.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_file(nodes, edges, prop=True, def_prop = 'interacts_with'):\n",
    "    '''\n",
    "    Transforms data into the correct format for the model\n",
    "    Input:\n",
    "    nodes, edges: data\n",
    "    prop: if there is a property associated with each edge\n",
    "    def_prop: property to be set\n",
    "    \n",
    "    Output: dataframe to be saved as csv\n",
    "    '''\n",
    "    \n",
    "    # get relevant info on entities/ prepare for merging\n",
    "    subject = nodes.copy()\n",
    "    object_ = nodes.copy()\n",
    "    try:\n",
    "        subject = subject.drop(columns=['semantic_groups'])\n",
    "        subject = subject.rename(columns={\"id\": \"subject_id\", \"preflabel\": \"subject_pl\", \"synonyms\": \"subject_syn\", \n",
    "                                          \"name\": \"subject_nm\", \"description\": \"subject_dsc\"})\n",
    "\n",
    "        object_ = object_.drop(columns=['semantic_groups'])\n",
    "        object_ = object_.rename(columns={\"id\": \"object_id\", \"preflabel\": \"object_pl\", \"synonyms\": \"object_syn\", \n",
    "                                          \"name\": \"object_nm\", \"description\": \"object_dsc\"})\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # combine entities with edges\n",
    "    merged1 = pd.merge(subject, edges, on='subject_id', how='right')\n",
    "    merged2 = pd.merge(object_, merged1, on='object_id', how='right')\n",
    "    print('merging worked:', len(merged1) == len(merged2))\n",
    "    \n",
    "    # fill nans with identifiers\n",
    "    merged2['object_pl'] = merged2['object_pl'].fillna(merged2['object_id'])\n",
    "    merged2['subject_pl'] = merged2['subject_pl'].fillna(merged2['subject_id'])\n",
    "    \n",
    "    if prop:\n",
    "        merged2['property_label'] = merged2['property_label'].fillna(merged2['property_id'])\n",
    "\n",
    "        # clean property label\n",
    "        merged2['property_label'] = merged2['property_label'].str.replace('biolink:', '')\n",
    "        merged2['property_label'] = merged2['property_label'].str.replace('_', ' ')\n",
    "        \n",
    "    else:\n",
    "        # keep only the 3 columns\n",
    "        merged2['property_label'] = def_prop\n",
    "        \n",
    "    # keep only the 3 columns\n",
    "    triplets = merged2[['subject_pl', 'property_label', 'object_pl']]\n",
    "    \n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALZHEIMERS\n",
    "triplets_ad = triplet_file(nodes_ad, edges_ad)\n",
    "# saving\n",
    "train, val = train_test_split(triplets_ad, test_size=0.2, random_state=42, shuffle=True)\n",
    "train.to_csv('data-avui/train.csv', sep='\\t', index=False)\n",
    "val.to_csv('data-avui/val.csv', sep='\\t', index=False)\n",
    "print(len(train) + len(val) == len(edges_ad))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "triplets_ad_dist = triplet_file(nodes_ad, ad_dist_edges)\n",
    "train_d, val_d = train_test_split(triplets_ad_dist, test_size=0.2, random_state=42, shuffle=True)\n",
    "train_d.to_csv('data-avui/train_ad.csv', sep='\\t', index=False)\n",
    "val_d.to_csv('data-avui/val_ad.csv', sep='\\t', index=False)\n",
    "print(len(train_d) + len(val_d) == len(ad_dist_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HUNTINGTON'S\n",
    "triplets_hd = triplet_file(nodes_hd, edges_hd)\n",
    "triplets_hd.to_csv('trip2.csv', index=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merging worked: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_pl</th>\n",
       "      <th>property_label</th>\n",
       "      <th>object_pl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TFR2</td>\n",
       "      <td>interacts_with</td>\n",
       "      <td>MSR1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RFC5</td>\n",
       "      <td>interacts_with</td>\n",
       "      <td>PLOD2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NUBPL</td>\n",
       "      <td>interacts_with</td>\n",
       "      <td>GNL2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADGRV1</td>\n",
       "      <td>interacts_with</td>\n",
       "      <td>SLC40A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UQCRFS1</td>\n",
       "      <td>interacts_with</td>\n",
       "      <td>MAPRE1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject_pl  property_label object_pl\n",
       "0       TFR2  interacts_with      MSR1\n",
       "1       RFC5  interacts_with     PLOD2\n",
       "2      NUBPL  interacts_with      GNL2\n",
       "3     ADGRV1  interacts_with   SLC40A1\n",
       "4    UQCRFS1  interacts_with    MAPRE1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PAIRS\n",
    "testing = triplet_file(nodes_hd, pred_pairs, prop=False)\n",
    "testing.to_csv('data/test.csv', index=None) \n",
    "# testing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DRUGS\n",
    "testing_d = triplet_file(nodes_ad, pred_pairs_drugs, prop=False)\n",
    "testing_d.to_csv('data/test_drugs.csv', index=None) \n",
    "# testing_d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merging worked: True\n",
      "merging worked: True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# ALZHEIMER'S + NEGATIVE\n",
    "triplets_ad = triplet_file(nodes_ad, edges_ad)\n",
    "\n",
    "df_neg = pd.read_csv(\"neg_p.csv\")\n",
    "neg = triplet_file(nodes_ad, df_neg, prop=False, def_prop='no interaction')\n",
    "ad = pd.concat([triplets_ad,neg])\n",
    "print(len(ad) == (len(triplets_ad)+len(neg)))\n",
    "\n",
    "train, val = train_test_split(ad, test_size=0.2, random_state=42, shuffle=True)\n",
    "train.to_csv('data/train_neg_tt.csv', sep='\\t', index=False)\n",
    "val.to_csv('data/val_neg_tt.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split to load to neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(edges_hd)/500000)\n",
    "one = edges_hd[:500000] #500,000\n",
    "two  = edges_hd[500000:1000000]\n",
    "three = edges_hd[1000000:]\n",
    "one.to_csv('data-neo4j/edges_hd_1.csv', index=False)\n",
    "two.to_csv('data-neo4j/edges_hd_2.csv', index=False)\n",
    "three.to_csv('data-neo4j/edges_hd_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.802744\n"
     ]
    }
   ],
   "source": [
    "print(len(edges_ad)/250000)\n",
    "one = edges_ad[:250000] #500,000\n",
    "two  = edges_ad[250000:500000]\n",
    "two_2  = edges_ad[500000:750000]\n",
    "two_3  = edges_ad[750000:1000000]\n",
    "three = edges_ad[1000000:1250000]\n",
    "three_2 = edges_ad[1250000:]\n",
    "one.to_csv('data-neo4j/edges_ad_1.csv', index=False)\n",
    "two.to_csv('data-neo4j/edges_ad_2.csv', index=False)\n",
    "two_2.to_csv('data-neo4j/edges_ad_3.csv', index=False)\n",
    "two_3.to_csv('data-neo4j/edges_ad_4.csv', index=False)\n",
    "three.to_csv('data-neo4j/edges_ad_5.csv', index=False)\n",
    "three_2.to_csv('data-neo4j/edges_ad_6.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
