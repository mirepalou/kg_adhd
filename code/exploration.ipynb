{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mirei\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\mirei\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "C:\\Users\\mirei\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n",
      "C:\\Users\\mirei\\Anaconda3\\lib\\site-packages\\pandas\\compat\\_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17083\n",
      "1356448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mirei\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py:3417: DtypeWarning: Columns (5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "nodes_hd = pd.read_csv('final data/graph_nodes_v2024-05-27.csv') #04-02\n",
    "edges_hd = pd.read_csv(\"final data/graph_edges_v2024-05-27.csv\") #04-02\n",
    "print(len(nodes_hd))\n",
    "print(len(edges_hd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17685\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1450686"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_ad = pd.read_csv('final data/alz_graph_nodes_v2024-05-25.csv')#\"ALZHEIMER/monarch_nodes_v2024-05-25.csv\")\n",
    "edges_ad = pd.read_csv('final data/alz_graph_edges_v2024-05-25.csv')#\"ALZHEIMER/monarch_edges_v2024-05-25.csv\")\n",
    "print(len(nodes_ad))\n",
    "len(edges_ad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is more than one kind of Alzheimer's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "alzh_ids = nodes_ad[(nodes_ad.preflabel.str.contains('Alzheimer')) & (nodes_ad.semantic_groups=='DISO')]\n",
    "print(len(alzh_ids))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "edges_ad[(edges_ad['object_id'].isin(list(alzh_ids.id))) & (edges_ad['subject_id'].isin(list(alzh_ids.id)))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning + Distribution relationships and semantic groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_hd['property_label'] = edges_hd['property_label'].fillna('NA')\n",
    "edges_hd['property_label'] = edges_hd['property_label'].str.replace('biolink:', '')\n",
    "edges_hd['property_label'] = edges_hd['property_label'].str.replace('_', ' ')\n",
    "# print(\"Relationships in the Huntington's graph\")\n",
    "# print(edges_hd['property_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_ad['property_label'] = edges_ad['property_label'].fillna('NA')\n",
    "edges_ad['property_label'] = edges_ad['property_label'].str.replace('biolink:', '')\n",
    "edges_ad['property_label'] = edges_ad['property_label'].str.replace('_', ' ')\n",
    "# print(\"Relationships in the Alzheimer's graph\")\n",
    "# print(edges_ad['property_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_ad['semantic_groups'] = nodes_ad['semantic_groups'].fillna('NA')\n",
    "# in case it is in the other graph\n",
    "na = nodes_ad[nodes_ad['semantic_groups'] == 'NA'].id\n",
    "for node in na:\n",
    "    nodes_ad.loc[nodes_ad.id == node, 'semantic_groups'] = list(nodes_hd[nodes_hd.id == node]['semantic_groups'])[0]\n",
    "\n",
    "nodes_ad['semantic_groups'] = nodes_ad['semantic_groups'].fillna('NA')\n",
    "   \n",
    "# print(nodes_ad['semantic_groups'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_hd['semantic_groups'] = nodes_hd['semantic_groups'].fillna('NA')\n",
    "# in case it is in the other graph\n",
    "na = nodes_hd[nodes_hd['semantic_groups'] == 'NA'].id\n",
    "for node in na:\n",
    "    nodes_hd.loc[nodes_hd.id == node, 'semantic_groups'] = list(nodes_ad[nodes_ad.id == node]['semantic_groups'])[0]\n",
    "    \n",
    "# print(nodes_hd['semantic_groups'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iron_nodes(nodes):\n",
    "    desc = nodes.dropna(subset=['description']) \n",
    "    iron = desc[desc.description.str.contains('iron')]\n",
    "\n",
    "    name = nodes.dropna(subset=['name']) \n",
    "    iron2 = name[name.name.str.contains('iron')]\n",
    "    \n",
    "    iron_t = pd.merge(iron, iron2, on=['id'], how='outer', indicator=False)\n",
    "    return iron_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True 141\n"
     ]
    }
   ],
   "source": [
    "iron_ad = iron_nodes(nodes_ad)\n",
    "iron_hd = iron_nodes(nodes_hd)\n",
    "print(len(set(list(iron_ad.id)).intersection(list(iron_hd.id))) == len(iron_ad), len(iron_ad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXPLORATION\n",
    "# get all the edges iron nodes - 1st neigh\n",
    "ed_ad = edges_ad[(edges_ad.subject_id.isin(list(iron_ad.id))) | (edges_ad.subject_id.isin(list(iron_ad.id)))]\n",
    "# connections iron - main seeds\n",
    "ids = ['MONDO:0007739', 'HGNC:182293', 'MONDO:0004975', 'HGNC:620', 'HGNC:2095', 'HGNC:6893','HGNC:933',' HGNC:613'] #seeds\n",
    "ed_i_ad = ed_ad[(ed_ad.subject_id.isin(ids)) | (ed_ad.object_id.isin(ids))]\n",
    "# print(len(ed_i_ad))\n",
    "# which are the most relevant iron nodes\n",
    "nodes_iron = nodes_ad[nodes_ad.id.isin(list(ed_i_ad.subject_id)) | nodes_ad.id.isin(list(ed_i_ad.object_id))]\n",
    "nodes_iron = nodes_iron[~nodes_iron.id.isin(ids)]\n",
    "len(nodes_iron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbor_nodes(ids, edges):\n",
    "    '''\n",
    "    Given a list of ids of nodes, get their neighbors\n",
    "    input:\n",
    "    ids: list with ids of nodes\n",
    "    edges: dataframe with the edges\n",
    "    \n",
    "    output:\n",
    "    nodes: set of ids of the neighbors\n",
    "    '''\n",
    "    ed_neigh = edges[(edges.subject_id.isin(ids)) | (edges.object_id.isin(ids))]\n",
    "#     print('Number of connections to the neighbors:', len(ed_neigh))\n",
    "    nodes = set(list(ed_neigh.subject_id)+list(ed_neigh.object_id))\n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Iron subgraph nodes: 6864\n",
      "Huntington's/HTT neighbor nodes: 501\n",
      "635\n",
      "484\n"
     ]
    }
   ],
   "source": [
    "# CANDIDATE PAIRS\n",
    "# nodes in cluster = iron + 1st neigh\n",
    "nodes_i_hd = get_neighbor_nodes(list(iron_hd.id), edges_hd)\n",
    "print('Initial Iron subgraph nodes:', len(nodes_i_hd))\n",
    "\n",
    "# nodes neighbors of huntington's (interesting)\n",
    "nodes_neigh_hd = get_neighbor_nodes(['MONDO:0007739', 'HGNC:4851'], edges_hd)\n",
    "print(\"Huntington's/HTT neighbor nodes:\", len(nodes_neigh_hd))\n",
    "\n",
    "# nodes_neigh_hd_2 = get_neighbor_nodes(nodes_neigh_hd, edges_hd)\n",
    "# print(\"Huntington's/HTT neighbor's neighbor nodes:\", len(nodes_neigh_hd_2))\n",
    "\n",
    "\n",
    "# only nodes that are iron - neighbors of HD\n",
    "keep = set(list(nodes_neigh_hd)  + list(iron_hd.id)) #+ list(nodes_neigh_hd_2)\n",
    "print(len(keep))\n",
    "candidate_nodes = [node for node in nodes_i_hd if node in keep] \n",
    "print(len(candidate_nodes))\n",
    "\n",
    "\n",
    "############################################################\n",
    "\n",
    "# # remove leaf nodes\n",
    "# degree_count = Counter(edges_ed_hd['subject_id']) + Counter(edges_ed_hd['object_id'])\n",
    "# leaf_nodes = [node for node, degree in degree_count.items() if degree == 1]\n",
    "# leaf_remove = [node for node in leaf_nodes if node not in list(iron_hd.id)]\n",
    "\n",
    "# nodes_connect = [node for node in nodes_ed_hd if node not in leaf_remove]\n",
    "# len(nodes_connect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56288\n"
     ]
    }
   ],
   "source": [
    "# Create a set of already connected pairs\n",
    "connected_pairs = set(zip(edges_hd['subject_id'], edges_hd['object_id'])) # | set(zip(edges_ad['subject_id'], edges_ad['object_id'])\n",
    "\n",
    "# Get all pairs that are not already connected\n",
    "pairs_i = set()\n",
    "list_ids = candidate_nodes\n",
    "n = len(list_ids)\n",
    "\n",
    "for i in range(n):\n",
    "    id_i = list_ids[i]\n",
    "    for j in range(i + 1, n):\n",
    "        id_j = list_ids[j]\n",
    "        if id_i in list(iron_hd.id) or id_j in list(iron_hd.id): #to reduce size, we constraint one of the nodes must be relevant\n",
    "            if (id_i, id_j) not in connected_pairs and (id_j, id_i) not in connected_pairs: #check the pair isnt already connected\n",
    "                pairs_i.add((id_i, id_j))\n",
    "\n",
    "print(len(pairs_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_pred_iron = pd.DataFrame(pairs_i, columns=['subject_id', 'object_id'])\n",
    "# pairs_pred.info()\n",
    "pairs_pred_iron.to_csv('pairs_pred_iron_neigh.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484\n",
      "484 484\n",
      "GENE    434\n",
      "DISO     39\n",
      "ANAT     10\n",
      "PHYS      1\n",
      "Name: semantic_groups, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#### analysis on the nodes selected\n",
    "\n",
    "test_iron = pairs_pred_iron# pd.read_csv('data/test_iron_reduced.csv')\n",
    "nodes_iron = set(list(test_iron.subject_id) + list(test_iron.object_id))\n",
    "print(len(nodes_iron))\n",
    "\n",
    "# merge with nodes so we can use the properties\n",
    "# nodes_hd = pd.read_csv('final data-kg/graph_nodes_v2024-05-27.csv') #04-02\n",
    "nodes_iron_hd1 = nodes_hd[nodes_hd.preflabel.isin(nodes_iron)]\n",
    "nodes_iron_hd2 = nodes_hd[nodes_hd.id.isin(nodes_iron)]\n",
    "nodes_iron_hd = pd.merge(nodes_iron_hd1, nodes_iron_hd2, how='outer')\n",
    "print(len(nodes_iron_hd), len(nodes_iron_hd1)+len(nodes_iron_hd2))\n",
    "\n",
    "nodes_iron_hd['semantic_groups'] = nodes_iron_hd['semantic_groups'].fillna('NA')\n",
    "print(nodes_iron_hd['semantic_groups'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(df, source, target):\n",
    "    G = nx.DiGraph()\n",
    "    # Add nodes from the 'source' and 'target' columns\n",
    "    G.add_nodes_from(df[source])\n",
    "    G.add_nodes_from(df[target])\n",
    "    # Add edges from the DataFrame\n",
    "    edges = [(row[source], row[target]) for index, row in df.iterrows()]\n",
    "    G.add_edges_from(edges)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_graph = create_graph(edges_ad, 'subject_id', 'object_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd_graph = create_graph(edges_hd, 'subject_id', 'object_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def degree(graph, nodes, top, plot=False, title=\"Huntington's\"):\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "#     print('degree absolute')\n",
    "    deg = graph.degree()\n",
    "    deg_s = dict(sorted(deg, key=lambda x:x[1], reverse=True)[:top])\n",
    "    \n",
    "#     print('degree centrality - fraction')\n",
    "    dc = nx.degree_centrality(graph)\n",
    "    dc = dict(sorted(dc.items(), key=lambda x:x[1], reverse=True)[:top])\n",
    " \n",
    "    for node_id in dc:\n",
    "        preflabel = nodes.loc[nodes['id'] == node_id, 'preflabel'].values[0] if node_id in nodes['id'].values else None        \n",
    "        df = df.append({'id': node_id,'preflabel': preflabel,'degree centrality': dc[node_id],'degree': deg[node_id] }, ignore_index=True)\n",
    "        \n",
    "    # plot\n",
    "    if plot == True:\n",
    "        degrees = dict(deg)\n",
    "        pos_degree_vals = list(filter(lambda val: val > 0, degrees.values())) # filtering nodes outdegree values with outdegree > 0\n",
    "        uq_pos_degree_vals = sorted(set(pos_degree_vals)) # getting unique and sorted outdegree values\n",
    "        hist = [pos_degree_vals.count(x) for x in uq_pos_degree_vals] # counting frequency of each outdegree values\n",
    "\n",
    "        x = np.asarray(uq_pos_degree_vals, dtype = float)\n",
    "        y = np.asarray(hist, dtype = float)\n",
    "\n",
    "        logx = np.log10(x)\n",
    "        logy = np.log10(y)\n",
    "\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.xlim(min(logx), max(logx))\n",
    "        plt.xlabel('log10 (Degree)')\n",
    "        plt.ylabel('log10 (Number of nodes)')\n",
    "        plt.title(\"Degree Distribution of\"+title)\n",
    "        degree_dist = plt.plot(logx, logy, 'o')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_hd = degree(hd_graph, nodes_hd, 5, plot=False, title=\"Huntington's\")\n",
    "metrics_hd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics_ad = pd.DataFrame()\n",
    "metrics_ad = degree(ad_graph, nodes_ad, 5, plot=False, title=\"Alzheimer's\")\n",
    "metrics_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# higher Closeness Centrality score indicates more central\n",
    "def closeness_centrality(graph, nodes):\n",
    "    df = pd.DataFrame()\n",
    "    clos = nx.closeness_centrality(graph)\n",
    "    close = dict(sorted(clos.items(), key=lambda x:x[1], reverse=True)[:5])\n",
    "    for node_id in close:\n",
    "        preflabel = nodes.loc[nodes['id'] == node_id, 'preflabel'].values[0] if node_id in nodes['id'].values else None        \n",
    "        df = df.append({'id': node_id,'preflabel': preflabel,'closeness': close[node_id] }, ignore_index=True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closeness = closeness_centrality(ad_graph, nodes_ad)\n",
    "closeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closeness = closeness_centrality(hd_graph, nodes_hd)\n",
    "closeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# higher betweenness Centrality score indicates more central\n",
    "def betweenness_centrality(graph, nodes, top=5):\n",
    "    df = pd.DataFrame()\n",
    "    betw = nx.betweenness_centrality(hd_graph)\n",
    "    betweenness = dict(sorted(betw.items(), key=lambda x:x[1])[:top])\n",
    "    for node_id in close:\n",
    "        preflabel = nodes.loc[nodes['id'] == node_id, 'preflabel'].values[0] if node_id in nodes['id'].values else None        \n",
    "        df = df.append({'id': node_id,'preflabel': preflabel,'betweenness': betweenness[node_id] }, ignore_index=True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betweenness = betweenness_centrality(ad_graph, nodes_ad, 5)\n",
    "betweenness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betweenness = betweenness_centrality(hd_graph, nodes_hd, 5)\n",
    "betweenness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding commonalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common nodes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# verify theres no repe\n",
    "print(len(list(nodes_hd.id)) == len(set(list(nodes_hd.id))))\n",
    "print(len(list(nodes_ad.id)) == len(set(list(nodes_ad.id))))\n",
    "\n",
    "#verify total nodes with repe\n",
    "len(list(nodes_ad.id)+ list(nodes_hd.id)) == len(list(nodes_ad.id))+ len(list(nodes_hd.id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_r = len(list(nodes_ad.id)+ list(nodes_hd.id))\n",
    "total = len(set(list(nodes_ad.id)+ list(nodes_hd.id)))\n",
    "common = (total_r - total)\n",
    "print('Total with repe:', total_r)\n",
    "print('Total wo repe:', total)\n",
    "print('In common ', common)\n",
    "dis_hd = len(nodes_hd.id) - common\n",
    "dis_ad = len(nodes_ad.id) - common\n",
    "print('Distinct HD', dis_hd)\n",
    "print('Distinct AD', dis_ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_f = pd.merge(nodes_ad, nodes_hd, on=['id'], how='inner', indicator=False)\n",
    "print(len(nodes_f) == common)\n",
    "# to correctly check the semantic groups\n",
    "nodes = nodes_hd[nodes_hd.id.isin(nodes_f.id)]\n",
    "print(nodes['semantic_groups'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd = edges_hd.drop_duplicates()\n",
    "ad = edges_ad.drop_duplicates()\n",
    "hd['subject_id'] = hd['subject_id'].astype(str)\n",
    "hd['object_id'] = hd['object_id'].astype(str)\n",
    "hd['property_id'] = hd['property_id'].astype(str)\n",
    "\n",
    "ad['subject_id'] = ad['subject_id'].astype(str)\n",
    "ad['object_id'] = ad['object_id'].astype(str)\n",
    "ad['property_id'] = ad['property_id'].astype(str)\n",
    "print(len(hd), len(ad))\n",
    "\n",
    "common_rows = hd.apply(tuple, 1).isin(ad.apply(tuple, 1))\n",
    "hd_distinct = hd[~hd.apply(tuple,1).isin(ad.apply(tuple,1))]\n",
    "ad_distinct = ad[~ad.apply(tuple,1).isin(hd.apply(tuple,1))]\n",
    "common = len(common_rows[common_rows == True])\n",
    "print('In common:', common)\n",
    "print('Only in HD:', len(hd_distinct), common+len(hd_distinct) == len(hd))\n",
    "print('Only in AD:',len(ad_distinct), common+len(ad_distinct) == len(ad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = hd[common_rows]\n",
    "cc['property_label'].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# common = hd - only hd\n",
    "print(edges_hd['property_label'].value_counts() - hd_distinct['property_label'].value_counts())\n",
    "print(edges_ad['property_label'].value_counts() - ad_distinct['property_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_distinct.to_csv('ad_edges.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO predict"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# different rows in hd\n",
    "diff = hd[~hd.apply(tuple, 1).isin(ad.apply(tuple, 1))]\n",
    "nod = set(list(diff.subject_id)+ list(diff.object_id))\n",
    "len(nod)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "nodes_predict = set(list(hd_distinct.subject_id)+list(hd_distinct.object_id))\n",
    "len(nodes_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_predict2 = nodes_hd[~nodes_hd.id.isin(nodes_f.id)]\n",
    "nodes_predict2.semantic_groups.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_predict2[nodes_predict2.preflabel.str.contains('Hunt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodes only in HD graph\n",
    "nodes_predict2 = nodes_hd[~nodes_hd.id.isin(nodes_f.id)]\n",
    "ids = list(nodes_predict2.id)\n",
    "\n",
    "# get all pairs that are not already connected\n",
    "pairs = []\n",
    "for i in range(len(ids)):\n",
    "    for j in range(len(ids)):\n",
    "        if i < j:\n",
    "            if len(edges_hd[(edges_hd.subject_id == ids[i]) & (edges_hd.object_id == ids[j])]) == 0:\n",
    "                if len(edges_hd[(edges_hd.subject_id == ids[j]) & (edges_hd.object_id == ids[i])]) == 0:\n",
    "                    pairs.append((ids[i], ids[j]))\n",
    "\n",
    "print(len(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_pred = pd.DataFrame(pairs, columns=['subject_id', 'object_id'])\n",
    "# pairs_pred.info()\n",
    "pairs_pred.to_csv('pairs_pred.csv', index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common phenotypes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# FIND COMMON PHENOTYPES\n",
    "pheno = cc[(cc['property_label'] == 'has phenotype')] #& (cc['subject_id'] == 'MONDO:0007739')\n",
    "diseases = nodes_hd[nodes_hd['id'].isin(list(pheno.subject_id))]\n",
    "phenotypes = nodes_hd[nodes_hd['id'].isin(list(pheno.object_id))]\n",
    "\n",
    "len(diseases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n",
      "47\n",
      "['Seizure', 'Agitation', 'Gait disturbance', 'Dystonia', 'Babinski sign', 'Memory impairment', 'Myoclonus', 'Dementia', 'Hallucinations', 'Disinhibition', 'Personality changes']\n"
     ]
    }
   ],
   "source": [
    "# FIND COMMON PHENOTYPES\n",
    "\n",
    "# phenotypes directly attached to HD\n",
    "pheno_h = edges_hd[(edges_hd['property_label'] == 'has phenotype') & (edges_hd['subject_id'] == 'MONDO:0007739')]\n",
    "phenotypes_h = nodes_hd[nodes_hd['id'].isin(list(pheno_h.object_id))]\n",
    "# phenotypes_h['preflabel'] = phenotypes_h['preflabel'].apply(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "print(len(phenotypes_h))\n",
    "\n",
    "# phenotypes directly attached to AD\n",
    "pheno_a = edges_ad[(edges_ad['property_label'] == 'has phenotype') & (edges_ad['subject_id'].isin(list(alzh_ids.id)))]\n",
    "phenotypes_a = nodes_ad[nodes_ad['id'].isin(list(pheno_a.object_id))]\n",
    "# phenotypes_a['preflabel'] = phenotypes_a['preflabel'].apply(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "print(len(phenotypes_a))\n",
    "\n",
    "# both have the same phenotypes\n",
    "phenotypes = pd.merge(phenotypes_a, phenotypes_h, on=['id'], how='inner', indicator=True)\n",
    "print(list(phenotypes.preflabel_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Treatments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treats = 'treats or applied or studied to treat'\n",
    "drugs_ad = edges_ad[(edges_ad.property_id.str.contains('treats')) & (edges_ad.object_id.isin(list(alzh_ids.id)))]\n",
    "drugs = nodes_ad[nodes_ad.id.isin(list(drugs_ad.subject_id))]\n",
    "# drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs_hd = edges_hd[(edges_hd.property_id.str.contains('treats'))& (edges_hd.object_id == 'MONDO:0007739')]\n",
    "drugs_hd = nodes_hd[nodes_hd.id.isin(list(drugs_hd.subject_id))]\n",
    "# drugs_hd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip = (set(list(drugs.id)).intersection(list(drugs_hd.id)))\n",
    "drugs_predict = pd.DataFrame()\n",
    "for drug in list(drugs.id):\n",
    "    if drug not in skip:\n",
    "        drugs_predict = drugs_predict.append({'subject_id': drug, 'object_id': 'MONDO:0007739'}, ignore_index=True)\n",
    "drugs_predict.to_csv('pairs_pred_drugs.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AD-> node: 171\n",
      "neighbors: 18\n",
      "neighbors connected to HD: 2\n",
      "neighbors not connected to HD, but in the graph: 11\n",
      "neighbors not in HD graph: 5\n",
      "['TREM2', 'inherited neurodegenerative disorder', 'hereditary dementia', 'tauopathy', 'autosomal dominant disease']\n"
     ]
    }
   ],
   "source": [
    "# first neighbors: AD -> node // AD -> exclusive ad node\n",
    "\n",
    "hd_conn = edges_hd[(edges_hd.subject_id == 'MONDO:0007739')|(edges_hd.object_id == 'MONDO:0007739')]\n",
    "nodes_hd_conn = nodes_hd[(nodes_hd.id.isin(list(hd_conn.subject_id))) | (nodes_hd.id.isin(list(hd_conn.object_id)))]\n",
    "\n",
    "ad_conn = edges_ad[(edges_ad['object_id'].isin(list(alzh_ids.id))) | (edges_ad['subject_id'].isin(list(alzh_ids.id)))]\n",
    "print('AD-> node:', len(ad_conn))\n",
    "# get rid of things we have explored already\n",
    "ad_conn = ad_conn[(ad_conn.property_id != 'biolink:has_phenotype') & (ad_conn.property_id != 'biolink:treats_or_applied_or_studied_to_treat')]\n",
    "nodes_ad_conn = nodes_ad[(nodes_ad.id.isin(list(ad_conn.subject_id))) | (nodes_ad.id.isin(list(ad_conn.object_id)))]\n",
    "\n",
    "diff_ad = nodes_ad_conn[~nodes_ad_conn.id.isin(list(alzh_ids.id))]\n",
    "print('neighbors:', len(diff_ad))\n",
    "\n",
    "\n",
    "diff2 = diff_ad[diff_ad.id.isin(list(nodes_hd_conn.id))]\n",
    "print('neighbors connected to HD:', len(diff2))\n",
    "\n",
    "diff1 = diff_ad[~diff_ad.id.isin(list(nodes_hd_conn.id))]\n",
    "diff1 = diff1[diff1.id.isin(list(nodes_hd.id))]\n",
    "print('neighbors not connected to HD, but in the graph:', len(diff1))\n",
    "\n",
    "diff = diff_ad[~diff_ad.id.isin(list(nodes_hd.id))]\n",
    "print('neighbors not in HD graph:', len(diff))\n",
    "\n",
    "print(list(diff.preflabel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>property_id</th>\n",
       "      <th>object_id</th>\n",
       "      <th>reference_uri</th>\n",
       "      <th>reference_supporting_text</th>\n",
       "      <th>reference_date</th>\n",
       "      <th>property_label</th>\n",
       "      <th>property_description</th>\n",
       "      <th>property_uri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>141234</th>\n",
       "      <td>HGNC:620</td>\n",
       "      <td>biolink:interacts_with</td>\n",
       "      <td>HGNC:25527</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/21244100</td>\n",
       "      <td>This edge comes from the Monarch Knowledge Gra...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>interacts with</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://purl.obolibrary.org/obo/biolink_interac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361990</th>\n",
       "      <td>HGNC:19679</td>\n",
       "      <td>biolink:interacts_with</td>\n",
       "      <td>HGNC:620</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/21832049</td>\n",
       "      <td>This edge comes from the Monarch Knowledge Gra...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>interacts with</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://purl.obolibrary.org/obo/biolink_interac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395104</th>\n",
       "      <td>HGNC:3008</td>\n",
       "      <td>biolink:interacts_with</td>\n",
       "      <td>HGNC:620</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/21832049</td>\n",
       "      <td>This edge comes from the Monarch Knowledge Gra...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>interacts with</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://purl.obolibrary.org/obo/biolink_interac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545263</th>\n",
       "      <td>HGNC:779</td>\n",
       "      <td>biolink:interacts_with</td>\n",
       "      <td>HGNC:620</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/21832049</td>\n",
       "      <td>This edge comes from the Monarch Knowledge Gra...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>interacts with</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://purl.obolibrary.org/obo/biolink_interac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152138</th>\n",
       "      <td>HGNC:28956</td>\n",
       "      <td>biolink:has_phenotype</td>\n",
       "      <td>HP:0000006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This edge comes from the Monarch Knowledge Gra...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>has phenotype</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://purl.obolibrary.org/obo/biolink_has_phe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         subject_id             property_id   object_id  \\\n",
       "141234     HGNC:620  biolink:interacts_with  HGNC:25527   \n",
       "361990   HGNC:19679  biolink:interacts_with    HGNC:620   \n",
       "395104    HGNC:3008  biolink:interacts_with    HGNC:620   \n",
       "545263     HGNC:779  biolink:interacts_with    HGNC:620   \n",
       "1152138  HGNC:28956   biolink:has_phenotype  HP:0000006   \n",
       "\n",
       "                                        reference_uri  \\\n",
       "141234   https://www.ncbi.nlm.nih.gov/pubmed/21244100   \n",
       "361990   https://www.ncbi.nlm.nih.gov/pubmed/21832049   \n",
       "395104   https://www.ncbi.nlm.nih.gov/pubmed/21832049   \n",
       "545263   https://www.ncbi.nlm.nih.gov/pubmed/21832049   \n",
       "1152138                                           NaN   \n",
       "\n",
       "                                 reference_supporting_text reference_date  \\\n",
       "141234   This edge comes from the Monarch Knowledge Gra...            NaN   \n",
       "361990   This edge comes from the Monarch Knowledge Gra...            NaN   \n",
       "395104   This edge comes from the Monarch Knowledge Gra...            NaN   \n",
       "545263   This edge comes from the Monarch Knowledge Gra...            NaN   \n",
       "1152138  This edge comes from the Monarch Knowledge Gra...            NaN   \n",
       "\n",
       "         property_label  property_description  \\\n",
       "141234   interacts with                   NaN   \n",
       "361990   interacts with                   NaN   \n",
       "395104   interacts with                   NaN   \n",
       "545263   interacts with                   NaN   \n",
       "1152138   has phenotype                   NaN   \n",
       "\n",
       "                                              property_uri  \n",
       "141234   http://purl.obolibrary.org/obo/biolink_interac...  \n",
       "361990   http://purl.obolibrary.org/obo/biolink_interac...  \n",
       "395104   http://purl.obolibrary.org/obo/biolink_interac...  \n",
       "545263   http://purl.obolibrary.org/obo/biolink_interac...  \n",
       "1152138  http://purl.obolibrary.org/obo/biolink_has_phe...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# second neighbors connections only in ad: common node --ad edge--> node (in both graphs)\n",
    "\n",
    "common_conn = list(nodes_hd[nodes_hd.id.isin(list(nodes_ad_conn.id))].id)\n",
    "\n",
    "sec_neigh_ad = edges_ad[(edges_ad.subject_id.isin(common_conn))|(edges_ad.object_id.isin(common_conn))]\n",
    "sec_neigh_hd = edges_hd[(edges_hd.subject_id.isin(common_conn))|(edges_hd.object_id.isin(common_conn))]\n",
    "sec_only_ad = sec_neigh_ad[~sec_neigh_ad.apply(tuple,1).isin(sec_neigh_hd.apply(tuple,1))]\n",
    "unseen_hd = sec_only_ad[(sec_only_ad.subject_id.isin(list(nodes_hd.id))) & (sec_only_ad.object_id.isin(list(nodes_hd.id)))]\n",
    "\n",
    "unseen_hd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
